# Server Configuration
AI_SIDECAR_HOST=0.0.0.0
AI_SIDECAR_PORT=8000

# Database Configuration
SURREALDB_URL=ws://localhost:8000/rpc
SURREALDB_NS=archer
SURREALDB_DB=main

# LLM Provider Configuration
LLM_PROVIDER=ollama  # Options: ollama, openai, anthropic, gemini

# Ollama Configuration (for local LLMs)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# OpenAI Configuration
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o

# Anthropic Configuration
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Google Gemini Configuration
GEMINI_API_KEY=
GEMINI_MODEL=gemini-1.5-pro

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# Logging Configuration
LOG_LEVEL=INFO  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
